# awesome-nlp
A curated list of resources dedicated to Natural Language Processing


Maintainers - [Keon Kim](http://github.com/keonkim)

## Table of Contents

 - [Codes](#codes)
 - [Libraries](#libraries)
   - [Node.js](#node.js)
   - [Java](#java)
   - [Python](#python)
   - [C++](#c++)
 - [Articles](#articles)
   - [Word Vectors](#word-vectors)
   - [Speech Recognition](#natural-langauge)
 - [Tutorials](#tutorials)
 - [Blogs](#blogs)
 - [Online Demos](#online-demos)

## Codes

## Libraries
* [Node.js](http://deeplearning.net/software/theano/) - Node.js Libaries for NLP
  * [natural](https://github.com/NaturalNode/natural) - general natural language facilities for node


## Articles
### Word Vectors
* [word2vec](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) - on creating vectors to represent language, useful for RNN inputs
* [sense2vec](http://arxiv.org/abs/1511.06388) - on word sense disambiguation
* [Infinite Dimensional Word Embeddings](http://arxiv.org/abs/1511.05392) - new
* [Skip Thought Vectors](http://arxiv.org/abs/1506.06726) - word representation method
* [Adaptive skip-gram](http://arxiv.org/abs/1502.07257) - similar approach, with adaptive properties

### Natural Language
* [Neural autocoder for paragraphs and documents](http://arxiv.org/abs/1506.01057) - LTSM representation
* [LTSM over tree structures](http://arxiv.org/abs/1503.04881)
* [Sequence to Sequence Learning](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) - word vectors for machine translation
* [Teaching Machines to Read and Comprehend](http://arxiv.org/abs/1506.03340) - DeepMind paper




part of the lists are from [ai-reading-list](https://github.com/m0nologuer/AI-reading-list)
